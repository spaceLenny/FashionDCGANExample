{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST DCGAN\n",
    "\n",
    "This DCGAN is loosely based on various tutorials I have found online. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set an optional output directory if you want to keep some in-progress generative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output = False\n",
    "\n",
    "if save_output:\n",
    "    !mkdir output\n",
    "    output_dir = 'output'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset\n",
    "\n",
    "You can download and unpack the FashionMNIST dataset here:\n",
    "\n",
    "https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "I suggest leaving it where it checks out, and modifying the path in the next cell. If you checked it out in this directory, the path below should work out of the box.\n",
    "\n",
    "Since FashionMNIST is a drop in replacement for MNIST, we can lean on the tensorflow mechanisms for train/test and batch generation for the rest of the notebook. Its pretty convenient.\n",
    "\n",
    "## if you run the next cell before you download the FashionMNIST dataset, it will download regular MNIST and you'll just get numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('fashion-mnist/data/fashion', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out a random sampling of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = np.random.randint(0, 1000, size=36)\n",
    "print(idx)\n",
    "fig, axes = plt.subplots(6, 6, sharex=True, sharey=True, figsize=(5,5),)\n",
    "for ii, ax in zip(idx, axes.flatten()):\n",
    "    ax.imshow(data.train.images[ii].reshape(28,28), aspect='equal', cmap='gray')\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x, feature_range=(-1, 1)):\n",
    "    # scale to (0, 1)\n",
    "    x = ((x - x.min())/(255 - x.min()))\n",
    "    \n",
    "    # scale to feature_range\n",
    "    min, max = feature_range\n",
    "    x = x * (max - min) + min\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Generator\n",
    "Builds up from the noise input. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, output_dim, reuse=False, alpha=0.2, training=True):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, 7*7*64)\n",
    "        # Reshape it to start the convolutional stack\n",
    "        x1 = tf.reshape(x1, (-1, 7, 7, 64))\n",
    "        x1 = tf.layers.batch_normalization(x1, training=training)\n",
    "        x1 = tf.maximum(alpha * x1, x1)\n",
    "        # 7x7x64 now\n",
    "\n",
    "        x2 = tf.layers.conv2d_transpose(x1, 32, 5, strides=2, padding='same')\n",
    "        x2 = tf.layers.batch_normalization(x2, training=training)\n",
    "        x2 = tf.maximum(alpha * x2, x2)\n",
    "        # 14x14x32 now\n",
    "        \n",
    "        x3 = tf.layers.conv2d_transpose(x2, 16, 5, strides=2, padding='same')\n",
    "        x3 = tf.layers.batch_normalization(x3, training=training)\n",
    "        x3 = tf.maximum(alpha * x3, x3)\n",
    "        # 28x28x16 now\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(x3, 1, 5, strides=1, padding='same')\n",
    "        # 28x28x1 now\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "This is basically just a convolutional classifier. The input to the discriminator are 28x28x1 images.\n",
    "\n",
    "Note that it hasn't been updated with the latest findings, and sticks closer to the DCGAN paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x, reuse=False, alpha=0.2):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "\n",
    "        d_x_image = tf.reshape(x, [-1,28,28,1])\n",
    "        \n",
    "        x1 = tf.layers.conv2d(d_x_image, 16, 5, strides=2, padding='same')\n",
    "        relu1 = tf.maximum(alpha * x1, x1)\n",
    "\n",
    "        x2 = tf.layers.conv2d(relu1, 32, 5, strides=2, padding='same')\n",
    "        bn2 = tf.layers.batch_normalization(x2, training=True)\n",
    "        relu2 = tf.maximum(alpha * bn2, bn2)\n",
    "\n",
    "        x3 = tf.layers.conv2d(relu2, 64, 5, strides=1, padding='same')\n",
    "        bn3 = tf.layers.batch_normalization(x3, training=True)\n",
    "        relu3 = tf.maximum(alpha * bn3, bn3)\n",
    "\n",
    "        flat = tf.reshape(relu3, (-1, 7*7*64))\n",
    "        logits = tf.layers.dense(flat, 1)\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loss\n",
    "\n",
    "There are a couple loss functions in here. Real images, generated images, and the fake one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, output_dim, alpha=0.2):\n",
    "   \n",
    "    g_model = generator(input_z, output_dim, alpha=alpha)\n",
    "    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True, alpha=alpha)\n",
    "\n",
    "    d_loss_real = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_model_real)))\n",
    "    d_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_model_fake)))\n",
    "    g_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake)))\n",
    "\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, real_size, z_size, learning_rate, alpha=0.2, beta1=0.5):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.input_real = tf.placeholder(tf.float32, (None, 28, 28), name='input_real')\n",
    "        self.input_z = tf.placeholder(tf.float32, (None, z_size), name='input_z')\n",
    "        \n",
    "        self.d_loss, self.g_loss = model_loss(self.input_real, self.input_z,\n",
    "                                              784, alpha=alpha)\n",
    "        \n",
    "        # Get weights and bias to update\n",
    "        self.t_vars = tf.trainable_variables()\n",
    "        self.d_vars = [var for var in self.t_vars if var.name.startswith('discriminator')]\n",
    "        self.g_vars = [var for var in self.t_vars if var.name.startswith('generator')]\n",
    "\n",
    "        # Build the independent Optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.d_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(self.d_loss, var_list=self.d_vars)\n",
    "            self.g_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(self.g_loss, var_list=self.g_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function for displaying generated images. I use it inline or save the figure to the output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_samples(epoch, samples, nrows, ncols, figsize=(5,5)):\n",
    "    fig, axes = plt.subplots(figsize=figsize, nrows=nrows, ncols=ncols, \n",
    "                             sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        ax.axis('off')\n",
    "        img = ((img - img.min())*255 / (img.max() - img.min())).astype(np.uint8)\n",
    "        ax.set_adjustable('box-forced')\n",
    "        im = ax.imshow(img.reshape(28, 28), aspect='equal', cmap=\"gray\")\n",
    "   \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataset, epochs, batch_size, figsize=(5,5)):\n",
    "    saver = tf.train.Saver()\n",
    "    sample_z = np.random.uniform(-1, 1, size=(72, z_size))\n",
    "\n",
    "    #capture a couple images along the way, and grab the losses so we can \n",
    "    #Graph them.\n",
    "    samples, losses = [], []\n",
    "    steps = 0\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(epochs):\n",
    "            for i in range(1000):\n",
    "                b, y = data.train.next_batch(batch_size)\n",
    "                x = b.reshape((batch_size, 28,28))\n",
    "                steps += 1\n",
    "\n",
    "                # Sample random noise for G\n",
    "                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "\n",
    "                # Run optimizers\n",
    "                \n",
    "                _ = sess.run(net.d_opt, feed_dict={net.input_real: x, net.input_z: batch_z})\n",
    "                _ = sess.run(net.g_opt, feed_dict={net.input_z: batch_z, net.input_real: x})\n",
    "\n",
    "                if steps % 500 == 0:\n",
    "                    # At the end of each epoch, get the losses and print them out\n",
    "                    train_loss_d = net.d_loss.eval({net.input_z: batch_z, net.input_real: x})\n",
    "                    train_loss_g = net.g_loss.eval({net.input_z: batch_z})\n",
    "\n",
    "                    print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "                          \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                    # Save losses to view after training\n",
    "                    losses.append((train_loss_d, train_loss_g))\n",
    "\n",
    "                # CHANGE THIS IF YOU WANT TO SEE MORE OR LESS FREQUENT IMAGES\n",
    "                if steps % 500 == 0:\n",
    "                    gen_samples = sess.run(generator(net.input_z, 3, reuse=True, training=False),\n",
    "                                   feed_dict={net.input_z: sample_z})\n",
    "                    samples.append(gen_samples)\n",
    "                    fig, _ = view_samples(-1, samples, 6, 12, figsize=figsize)\n",
    "                    if save_output:\n",
    "                        fig.savefig(\"./\" + output_dir + '/' + str(e) + \"_\" + str(steps) + \"_img.png\")\n",
    "                    else:\n",
    "                        plt.show()\n",
    "                    plt.close(fig)\n",
    "\n",
    "        saver.save(sess, './fashion/generator.ckpt')\n",
    "\n",
    "    with open('samples.pkl', 'wb') as f:\n",
    "        pkl.dump(samples, f)\n",
    "    \n",
    "    return losses, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "GANs are very sensitive to hyperparameters.\n",
    "Check out [the DCGAN paper](https://arxiv.org/pdf/1511.06434.pdf) - these are rough approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_size = (28, 28)\n",
    "z_size = 100\n",
    "learning_rate = 0.0002\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "alpha = 0.2\n",
    "beta1 = 0.5\n",
    "\n",
    "# Create & train the network\n",
    "net = GAN(real_size, z_size, learning_rate, alpha=alpha, beta1=beta1)\n",
    "losses, samples = train(net, None, epochs, batch_size, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = view_samples(-1, samples, 6, 12, figsize=(10,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
